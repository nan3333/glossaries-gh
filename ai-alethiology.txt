Truthful AI
    [[calibredb:207]]

narrow truthfulness

broad truthfulness

strategic selection power

    Linguistic AI systems today have little
    strategic selection power, and mostly
    produce statements that are not that
    useful (whether true or false).
    
    More strategic selection power on
    statements provides the possibility of
    useful statements, but also of harmful
    lies.

selection power

negligent falsehoods

    A generalisation of lies that is easier to
    assess.

standard
truthfulness standard

    Standards can be domain-specific.
    
    (For example, users may want different
    truth- fulness standards for AI that
    provides legal information than for AI
    that rec- ommends TV shows.) It might be
    desirable for some minimum standard to be
    widely applicable, e.g.
    
    to all commercial uses of linguistic AI.
    
    But this isnâ€™t to say that all AI systems
    should be truthful.
    
    To take one example, it could be
    beneficial for AI researchers to use and
    study non-truthful systems, and such
    systems might not pose much of a risk if
    they only ever interacted with their own
    developers.
    
    Exceptions to truthfulness standards are
    discussed more in Section 3.

    There are a few different dimensions on which standards can vary:
    - A standard can be higher or lower. A
      high standard is more demanding and
      requires a greater minimum level of
      truthfulness.
    - A standard can be more or less widely
      adhered to, within the domain where it
      applies.
    - Failure to comply with a standard can
      result in different kinds of sanctions,
      either formal (e.g. specified in law) or
      informal (e.g. as a result of social
      norms).

