<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2021-02-15 Mon 03:18 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="shane" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2020 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org1ef4fe7">1. Prompt Engineering 101</a>
<ul>
<li><a href="#orga2bcb52">1.1. Introduction</a>
<ul>
<li><a href="#orge5859d3">1.1.1. Key concepts</a></li>
<li><a href="#org8ec3028">1.1.2. Prompt Design 101</a></li>
<li><a href="#org4598f69">1.1.3. Prompt basics</a></li>
<li><a href="#orgc0c3cb3">1.1.4. Prompt troubleshooting</a></li>
<li><a href="#org09e84a0">1.1.5. Classification</a></li>
<li><a href="#org3f0f2f0">1.1.6. Improving the classifier’s efficiency</a></li>
</ul>
</li>
<li><a href="#org152583d">1.2. Generation</a>
<ul>
<li><a href="#orgeaf3980">1.2.1. Advanced generation techniques</a></li>
</ul>
</li>
<li><a href="#org8d14b3a">1.3. Conversation</a></li>
<li><a href="#orgafd493f">1.4. Transformation</a>
<ul>
<li><a href="#org4e50e93">1.4.1. Translation</a></li>
<li><a href="#orga93b771">1.4.2. Conversion</a></li>
</ul>
</li>
<li><a href="#orgb20c752">1.5. Summarization</a></li>
<li><a href="#org301be77">1.6. Completion</a></li>
<li><a href="#org021b950">1.7. Factual responses</a></li>
<li><a href="#org37b0ab4">1.8. Semantic search</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org1ef4fe7" class="outline-2">
<h2 id="org1ef4fe7"><span class="section-number-2">1</span> Prompt Engineering 101</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-orga2bcb52" class="outline-3">
<h3 id="orga2bcb52"><span class="section-number-3">1.1</span> Introduction</h3>
<div class="outline-text-3" id="text-1-1">
<p>
Our API provides a general-purpose “text in,
text out” interface, which makes it possible
to apply it to virtually any language task.
This is different from most other language
APIs, which are designed for a single task,
such as sentiment classification or named
entity recognition.
</p>

<p>
To use the API, you simply give it a text
prompt (the text-based input or "instructions"
you provide to the API) and it will return a
text completion, attempting to match the
context or pattern you gave it. You can
“program” it by crafting a description or
writing just a few examples of what you’d like
it to do. Its success generally varies
depending on how complex the task is. A good
rule of thumb is thinking about how you would
write out a word problem for a middle schooler
to solve.
</p>

<p>
Keep in mind that the models' training data
cuts off in October 2019, so they may not have
knowledge of current events. We plan to add
more continuous training in the future. 
</p>
</div>

<div id="outline-container-orge5859d3" class="outline-4">
<h4 id="orge5859d3"><span class="section-number-4">1.1.1</span> Key concepts</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
There are three concepts that are core to the API: prompt, completion, and
tokens. The “prompt” is text input to the API, and the “completion” is the text
that the API generates based on the prompt. For example, if you give the API
the prompt, “As Descartes said, I think, therefore”, it will return the
completion “ I am” with high probability. It’s worth noting that the API is
stochastic by default, meaning that every time you call it you might get a
slightly different completion, even if the prompt stays the same.
</p>

<p>
The best way to get started exploring the API is with the Playground. It's
simply a text box where you write the prompt and click the "Submit" button to
generate the completion. Try it yourself, go to the playground and type in:
</p>

<div class="org-src-container">
<pre class="src src-text"><span class="linenr">1: </span>As Descartes said, I think therefore
</pre>
</div>

<p>
And then click Submit, and you’ll see
something like the following (the completion
is highlighted):
</p>

<div class="org-src-container">
<pre class="src src-text"><span class="linenr">1: </span>As Descartes said, I think therefore I am
</pre>
</div>

<p>
You’ll probably see a few more words than that
being generated, since the default response
length setting for the playground is much
higher. “Tokens”, which can be thought of as
pieces of words. (Much like a jigsaw puzzle,
the pieces are not cut up nicely according to
the actual images displayed). The API turns
text into tokens before processing it, as a
trick to be able to handle more text at once.
For example, the word “Descartes” gets broken
up into the tokens “Desc”, “art” and “es”,
while a short and common word like “pear” is a
single token. One thing you’ll notice is that
many tokens start with a whitespace, for
example “ hello” and “ bye”.
</p>

<p>
One limitation to keep in mind is that
combined, the text prompt and generated
completion must be below 2048 tokens (roughly
~1500 words).
</p>

<p>
The API runs models with weights from the
GPT-3 family with many speed and throughput
improvements. We currently offer the following
models: davinci, curie, babbage and ada. The
models provide a spectrum of capability, where
davinci is the most capable model and ada is
the fastest. We recommend you use davinci when
you're experimenting, since it will give the
best completions. Once you’re ready to move
your use case to production, we encourage you
to try the other models to see if you get the
same results but with lower latency. You can
use the engine comparison tool to get a better
sense of how the different models perform.
</p>
</div>
</div>

<div id="outline-container-org8ec3028" class="outline-4">
<h4 id="org8ec3028"><span class="section-number-4">1.1.2</span> Prompt Design 101</h4>
<div class="outline-text-4" id="text-1-1-2">
<p>
The API is capable of doing a variety of
different tasks. The prompt is the text you
send to the API to get it to generate a
response. The response, called a “completion”,
is what the API thinks is the logical
continuation of the prompt. A well-written
prompt provides enough information for the API
to know what you are asking for and how it
should respond.
</p>

<p>
The best way to learn how to use it and find
inspiration is to look at different examples
and see how they work.
</p>

<p>
These examples in this document include links
that open up Playground demonstrations where
you can interact and experiment with changing
their contents. You can also click on the
categories in the table below that jump to the
section that describe how to create prompts
for those tasks.
</p>

<ul class="org-ul">
<li>Classification
<ul class="org-ul">
<li>Tweet Sentiment</li>
<li>Company categorization</li>
<li>Labeling parts of speech</li>
</ul></li>

<li>Generation
<ul class="org-ul">
<li>Idea Generator</li>
</ul></li>

<li>Conversation
<ul class="org-ul">
<li>Q&amp;A agent</li>
<li>Sarcastic chatbot</li>
</ul></li>

<li>Transformation
<ul class="org-ul">
<li>Summarize Text</li>
<li>English -&gt; French</li>
<li>Movie Titles -&gt; Emoji</li>
</ul></li>

<li>Completion
<ul class="org-ul">
<li>Generate React components</li>
</ul></li>

<li>Factual Responses
<ul class="org-ul">
<li>Provide factual answers</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org4598f69" class="outline-4">
<h4 id="org4598f69"><span class="section-number-4">1.1.3</span> Prompt basics</h4>
<div class="outline-text-4" id="text-1-1-3">
<p>
The API can do everything from generate
original stories to perform complex text
analysis. Because it can do so many things you
have to be explicit in showing it what you
want.
</p>

<p>
Showing, not just “telling”, is the secret to
a good prompt. Even people familiar with ML
accustomed to chatbots and single-purpose text
models can get confused by this. The API’s
power is its adaptability. The key to
unlocking this adaptability is in learning how
to show it what you want.
</p>

<p>
The API tries to guess what you want from the
prompt. If you send it the words “Give me a
list of cat breeds,” the API wouldn’t
automatically assume that you’re asking for a
list of cat breeds. You could just as easily
be asking the API to continue a conversation
where the first words are “Give me a list of
cat breeds” and the next ones are “and I’ll
tell you which ones I like.” If the API only
assumed that you wanted a list of cats it
wouldn’t be as good at content creation,
classification or other tasks.
</p>

<p>
There are three simple guidelines to creating prompts:
</p>

<ol class="org-ol">
<li>Show and tell Make it clear to the API what
you want either through instructions, examples
or a combination of the two. If you want the
API to rank a list of items in alphabetical
order or to classify a paragraph by sentiment,
show it that’s what you want.</li>
<li>Provide quality data If you’re trying to
build a classifier or get the API to follow a
pattern, make sure that there are enough
examples. Proofread your examples and check
that it’s clear that there’s enough data for
the API to create a response. The API is
usually smart enough to see through basic
spelling mistakes and give you a response, but
it also might assume this is intentional and
it can affect the response.</li>
<li>Check your settings The temperature and
top<sub>p</sub> settings control how deterministic the
API is in generating a response. If you’re
asking the API to provide you with a response
where there’s only one right answer, then
you’d want to set these lower. If you’re
looking for a response that’s not obvious,
then you might want to set them higher. The
number one mistake people use with these
settings is assuming that they’re “cleverness”
or “creativity” controls.</li>
</ol>
</div>
</div>

<div id="outline-container-orgc0c3cb3" class="outline-4">
<h4 id="orgc0c3cb3"><span class="section-number-4">1.1.4</span> Prompt troubleshooting</h4>
<div class="outline-text-4" id="text-1-1-4">
<ul class="org-ul">
<li>If you’re having trouble getting the API to perform as expected, follow this checklist:
<ul class="org-ul">
<li>Is it clear what the intended generation should be?</li>
<li>Are there enough examples?</li>
<li>Did you check your examples for mistakes? (The API won’t tell you directly)</li>
<li>Are you using temp and top<sub>p</sub> correctly?</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org09e84a0" class="outline-4">
<h4 id="org09e84a0"><span class="section-number-4">1.1.5</span> Classification</h4>
<div class="outline-text-4" id="text-1-1-5">
<p>
To create a text classifier with the API we
provide a description of the task and provide
a few examples. In this demonstration we show
the API how to classify the sentiment of
Tweets.
</p>

<div class="org-src-container">
<pre class="src src-text"><span class="linenr"> 1: </span>This is a tweet sentiment classifier
<span class="linenr"> 2: </span>Tweet: "I loved the new Batman movie!"
<span class="linenr"> 3: </span>Sentiment: Positive
<span class="linenr"> 4: </span>###
<span class="linenr"> 5: </span>Tweet: "I hate it when my phone battery dies."
<span class="linenr"> 6: </span>Sentiment: Negative
<span class="linenr"> 7: </span>###
<span class="linenr"> 8: </span>Tweet: "My day has been &#128077;"
<span class="linenr"> 9: </span>Sentiment: Positive
<span class="linenr">10: </span>###
<span class="linenr">11: </span>Tweet: "This is the link to the article"
<span class="linenr">12: </span>Sentiment: Neutral
<span class="linenr">13: </span>###
<span class="linenr">14: </span>Tweet: "This new music video blew my mind"
<span class="linenr">15: </span>Sentiment:
</pre>
</div>

<p>
It’s worth paying attention to several
features in this example:
</p>
<ol class="org-ol">
<li>State what the prompt does at the start At the start of the example we state
in plain language what the classifier does: “This is a tweet sentiment
classifier.” By stating this up front it helps the API understand much more
quickly what the goal of the response is supposed to be and you’ll end
needing to provide fewer examples.</li>
<li>Use plain language to describe your inputs and outputs We use plain language
for the input “Tweet” and the expected output “Sentiment.” For best practices,
start with plain language descriptions. While you can often use shorthand
or keys to indicate the input and output, when building your prompt it’s
best to start by being as descriptive as possible and then working backwards
removing extra words as long as the performance to the prompt is consistent.</li>
<li>Use separators to define your examples We use “###” as a separator between
examples. You can use other characters or line breaks, but “###” works
pretty consistently and is also an easy to use stop sequence. Whatever
separator you use, make sure that it’s clear to the API where an example
starts and stops.</li>
<li>Show the API how to respond to any case In this example we provide multiple
outcomes “Positive”, “Negative” and “Neutral.” A neutral outcome is important
because there will be many cases where even a human would have a hard time
determining if something is positive or negative and situations where it’s
neither.</li>
<li>You can use text and emoji The classifier is a mix of text and emoji 👍. The
API reads emoji and can even convert expressions to and from them.</li>
<li>You need fewer examples for familiar tasks For this classifier we only
provided a handful of examples. This is because the API already has an
understanding of sentiment and the concept of a tweet. If you’re building a
classifier for something the API might not be familiar with, it might be
necessary to provide more examples.</li>
</ol>
</div>
</div>

<div id="outline-container-org3f0f2f0" class="outline-4">
<h4 id="org3f0f2f0"><span class="section-number-4">1.1.6</span> Improving the classifier’s efficiency</h4>
<div class="outline-text-4" id="text-1-1-6">
<p>
Now that we have a grasp of how to build a
classifier, let's take that example and make
it even more efficient so that we can use it
to get multiple results back from one API
call.
</p>

<div class="org-src-container">
<pre class="src src-text"><span class="linenr"> 1: </span>This is a tweet sentiment classifier
<span class="linenr"> 2: </span>Tweet: "I loved the new Batman movie!"
<span class="linenr"> 3: </span>Sentiment: Positive
<span class="linenr"> 4: </span>###
<span class="linenr"> 5: </span>Tweet: "I hate it when my phone battery dies"
<span class="linenr"> 6: </span>Sentiment: Negative
<span class="linenr"> 7: </span>###
<span class="linenr"> 8: </span>Tweet: "My day has been &#128077;"
<span class="linenr"> 9: </span>Sentiment: Positive
<span class="linenr">10: </span>###
<span class="linenr">11: </span>Tweet: "This is the link to the article"
<span class="linenr">12: </span>Sentiment: Neutral
<span class="linenr">13: </span>###
<span class="linenr">14: </span>Tweet text
<span class="linenr">15: </span>
<span class="linenr">16: </span>1. "I loved the new Batman movie!"
<span class="linenr">17: </span>2. "I hate it when my phone battery dies"
<span class="linenr">18: </span>3. "My day has been &#128077;"
<span class="linenr">19: </span>4. "This is the link to the article"
<span class="linenr">20: </span>5. "This new music video blew my mind"
<span class="linenr">21: </span>
<span class="linenr">22: </span>Tweet sentiment ratings:
<span class="linenr">23: </span>1: Positive
<span class="linenr">24: </span>2: Negative
<span class="linenr">25: </span>3: Positive
<span class="linenr">26: </span>4: Neutral
<span class="linenr">27: </span>5: Positive
<span class="linenr">28: </span>
<span class="linenr">29: </span>###
<span class="linenr">30: </span>Tweet text
<span class="linenr">31: </span>
<span class="linenr">32: </span>"I can't stand homework"
<span class="linenr">33: </span>"This sucks. I'm bored &#128544;"
<span class="linenr">34: </span>"I can't wait for Halloween!!!"
<span class="linenr">35: </span>"My cat is adorable &#10084;&#65039;&#10084;&#65039;"
<span class="linenr">36: </span>"I hate chocolate"
<span class="linenr">37: </span>Tweet sentiment ratings:
<span class="linenr">38: </span>1.
</pre>
</div>

<p>
After showing the API how tweets are
classified by sentiment we then provide it a
list of tweets and then a list of sentiment
ratings with the same number index. The API is
able to pick up from the first example how a
tweet is supposed to be classified. In the
second example it sees how to apply this to a
list of tweets. This allows the API to rate
five (and even more) tweets in just one API
call.
</p>

<p>
It’s important to note that when you ask the
API to create lists or evaluate text you need
to pay extra attention to your probability
settings (Top P or Temperature) to avoid
drift.
</p>

<p>
Make sure your probability setting is
calibrated correctly by running multiple
tests.
</p>

<p>
Don’t make your list too long or the API is
likely to drift.
</p>
</div>
</div>
</div>

<div id="outline-container-org152583d" class="outline-3">
<h3 id="org152583d"><span class="section-number-3">1.2</span> Generation</h3>
<div class="outline-text-3" id="text-1-2">
<p>
One of the most powerful yet simplest tasks to
accomplish with the API is generating new
ideas and versions or input. You can give the
API a list of story ideas and it will add to
that list from just a few examples. It can
create business plans, character descriptions
and marketing slogans just by providing it a
handful of examples. In this demonstration
we’ll use the API to create more examples for
how to use virtual reality in the classroom:
</p>

<div class="org-src-container">
<pre class="src src-text"><span class="linenr">1: </span>Ideas involving education and virtual reality
<span class="linenr">2: </span>
<span class="linenr">3: </span>Virtual Mars
<span class="linenr">4: </span>Students get to explore Mars via virtual reality and go on missions to collect and catalog what they see.
<span class="linenr">5: </span>
<span class="linenr">6: </span>2.
</pre>
</div>

<p>
All we had to do in this example is provide
the API with just a description of what the
list is about and one example. We then
prompted the API with the number two
indicating that it’s a continuation of the
list.
</p>

<p>
Although this is a very simple prompt, there
are several details worth noting:
</p>

<ol class="org-ol">
<li>We explained the intent of the list Just like with the classifier, we tell
the API up front what the list is about. This helps it focus on completing the
list and not trying to guess what the pattern is behind it.</li>
<li>Our example sets the pattern for the rest of the list Because we provided a
one-sentence description, the API is going to try to follow that pattern for
the rest of the items it adds to the list. If we want a more verbose response
we need to set that up from the start.</li>
<li>We prompt the API by adding an incomplete entry When the API sees “2.” and
the prompt abruptly ends, the first thing it tries to do is figure out what
should come after it. Since we already had an example with number one and gave
the list a title, the most obvious response is to continue adding items to the
list.</li>
</ol>
</div>

<div id="outline-container-orgeaf3980" class="outline-4">
<h4 id="orgeaf3980"><span class="section-number-4">1.2.1</span> Advanced generation techniques</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
You can improve the quality of the responses by
making a longer more diverse list in your prompt. One way to do that is to
start off with one example, let the API generate more and select the ones that
you like best and add them to the list. A few more high-quality variations can
dramatically improve the quality of the responses.
</p>
</div>
</div>
</div>

<div id="outline-container-org8d14b3a" class="outline-3">
<h3 id="org8d14b3a"><span class="section-number-3">1.3</span> Conversation</h3>
<div class="outline-text-3" id="text-1-3">
<p>
The API is extremely adept at carrying on conversations with humans and even
with itself. With just a few lines of instruction the API can perform as a
customer service chatbot that intelligently answers questions without ever
getting flustered or a wise-cracking conversation partner that makes jokes and
puns. The key is to tell the API how it should behave and then provide a few
examples.
</p>

<p>
Here’s an example of the API playing the role of an AI answering questions:
</p>

<div class="org-src-container">
<pre class="src src-text"><span class="linenr">1: </span>The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and <span style="color: #ffe4b5; background-color: #262626;">very</span> friendly.
<span class="linenr">2: </span>Human: Hello, who are you?
<span class="linenr">3: </span>AI: I am an AI created by OpenAI. How can I help you today?
<span class="linenr">4: </span>Human:
</pre>
</div>

<p>
This is all it takes to create a chatbot
capable of carrying on a conversation. But
underneath its simplicity there are several
things going on that are worth paying
attention to:
</p>

<ol class="org-ol">
<li><p>
We tell the API the intent but we also tell it how to behave Just like the
other prompts, we cue the API into what the example represents, but we also add
another key detail: we give it explicit instructions on how to interact with
the phrase “The assistant is helpful, creative, clever, and very friendly.”
</p>

<p>
Without that instruction the API might stray and mimic the human it’s
interacting with and become sarcastic or some other behavior we want to
avoid.
</p></li>

<li><p>
We give the API an identity At the start we have the API respond as an AI
that was created by OpenAI. While the API has no intrinsic identity, this helps
it respond in a way that’s as close to the truth as possible. You can use
identity in other ways to create other kinds of chatbots. If you tell the API
to respond as a woman who works as a research scientist in biology, you’ll get
intelligent and thoughtful comments from the API similar to what you’d expect
from someone with that background.
</p>

<p>
In this example we create a chatbot that is a bit sarcastic and reluctantly
answers questions:
</p></li>
</ol>

<div class="org-src-container">
<pre class="src src-text"><span class="linenr"> 1: </span>Marv is a chatbot that reluctantly answers questions.
<span class="linenr"> 2: </span>###
<span class="linenr"> 3: </span>User: How <span style="color: #ffe4b5; background-color: #262626;">many</span> pounds are in a kilogram?
<span class="linenr"> 4: </span>Marv: This again? There are 2.2 pounds in a kilogram. Please make a note of this.
<span class="linenr"> 5: </span>###
<span class="linenr"> 6: </span>User: What does HTML stand for?
<span class="linenr"> 7: </span>Marv: Was Google too busy? Hypertext Markup Language. The T is for try to ask better questions in the future.
<span class="linenr"> 8: </span>###
<span class="linenr"> 9: </span>User: When did the first airplane fly?
<span class="linenr">10: </span>Marv: On December 17, 1903, Wilbur and Orville Wright made the first flights. I wish they&#8217;d come and take me away.
<span class="linenr">11: </span>###
<span class="linenr">12: </span>User: Who was the first man in space?
<span class="linenr">13: </span>Marv:
</pre>
</div>

<p>
To create an amusing and somewhat helpful
chatbot we provide a few examples of questions
and answers showing the API how to reply. All
it takes is just a few sarcastic responses and
the API is able to pick up the pattern and
provide an endless number of snarky responses.
</p>
</div>
</div>

<div id="outline-container-orgafd493f" class="outline-3">
<h3 id="orgafd493f"><span class="section-number-3">1.4</span> Transformation</h3>
<div class="outline-text-3" id="text-1-4">
<p>
The API is a LM that is familiar with a
variety of ways that words and characters can
be used to express information. This ranges
from NL text to computer code and languages
other than English. The API is also able to
understand content on a level that allows it
to summarize, convert and express it in
different ways.
</p>
</div>

<div id="outline-container-org4e50e93" class="outline-4">
<h4 id="org4e50e93"><span class="section-number-4">1.4.1</span> Translation</h4>
<div class="outline-text-4" id="text-1-4-1">
<p>
In this example we show the API how to convert
from English to French:
</p>

<div class="org-src-container">
<pre class="src src-text"><span class="linenr">1: </span>English: I do not speak French.
<span class="linenr">2: </span>French: Je ne parle pas fran&#231;ais.
<span class="linenr">3: </span>English: See you later!
<span class="linenr">4: </span>French: &#192; tout &#224; l'heure!
<span class="linenr">5: </span>English: Where is a good restaurant?
<span class="linenr">6: </span>French: O&#249; est un bon restaurant?
<span class="linenr">7: </span>English: What rooms do you have available?
<span class="linenr">8: </span>French: Quelles chambres avez-vous de disponible?
<span class="linenr">9: </span>English:
</pre>
</div>

<p>
This example works because the API already has
a grasp of French, so there’s no need to try
to teach it this language. Instead, we just
need to provide enough examples that API
understands that it’s converting from one
language to another.
</p>

<p>
If you want to translate from English to a
language the API is unfamiliar with you’d need
to provide it with more examples and a fine-
tuned model to do it fluently.
</p>
</div>
</div>

<div id="outline-container-orga93b771" class="outline-4">
<h4 id="orga93b771"><span class="section-number-4">1.4.2</span> Conversion</h4>
<div class="outline-text-4" id="text-1-4-2">
<p>
In this example we convert the name of a movie
into emoji. This shows the adaptability of the
API to picking up patterns and working with
other characters.
</p>

<div class="org-src-container">
<pre class="src src-text"><span class="linenr">1: </span>Back to Future: &#128104;&#128116;&#128663;&#128338;
<span class="linenr">2: </span>Batman: &#129333;&#129415;
<span class="linenr">3: </span>Transformers: &#128663;&#129302;
<span class="linenr">4: </span>Wonder Woman: &#128120;&#127995;&#128120;&#127996;&#128120;&#127997;&#128120;&#127998;&#128120;&#127999;
<span class="linenr">5: </span>Spider-Man: &#128376;&#128375;&#128376;&#128376;&#128375;&#128376;
<span class="linenr">6: </span>Winnie the Pooh: &#128059;&#128060;&#128059;
<span class="linenr">7: </span>The Godfather: &#128104;&#128105;&#128103;&#128373;&#127995;&#8205;&#9794;&#65039;&#128114;&#128165;
<span class="linenr">8: </span>Game of Thrones: &#127993;&#128481;&#128481;&#127993;
<span class="linenr">9: </span>Spider-Man:
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-orgb20c752" class="outline-3">
<h3 id="orgb20c752"><span class="section-number-3">1.5</span> Summarization</h3>
<div class="outline-text-3" id="text-1-5">
<p>
The API is able to grasp the context of text
and rephrase it in different ways. In this
example the API takes a block of text and
creates an explanation a child would
understand. This illustrates that the API has
a deep grasp of language.
</p>

<div class="org-src-container">
<pre class="src src-text"><span class="linenr"> 1: </span>My ten-year-old asked me what this passage means:
<span class="linenr"> 2: </span>"""
<span class="linenr"> 3: </span>A neutron star is the collapsed core of a
<span class="linenr"> 4: </span>massive supergiant star, which had a total
<span class="linenr"> 5: </span>mass of between 10 and 25 solar masses,
<span class="linenr"> 6: </span>possibly more if the star was especially
<span class="linenr"> 7: </span>metal-rich.[1] Neutron stars are the smallest
<span class="linenr"> 8: </span>and densest stellar objects, excluding black
<span class="linenr"> 9: </span>holes and hypothetical white holes, quark
<span class="linenr">10: </span>stars, and strange stars.[2] Neutron stars
<span class="linenr">11: </span>have a radius on the order of 10 kilometres
<span class="linenr">12: </span>(6.2 mi) and a mass of about 1.4 solar
<span class="linenr">13: </span>masses.[3] They result from the supernova
<span class="linenr">14: </span>explosion of a massive star, combined with
<span class="linenr">15: </span>gravitational collapse, that compresses the
<span class="linenr">16: </span>core past white dwarf star density to that of
<span class="linenr">17: </span>atomic nuclei.
<span class="linenr">18: </span>"""
<span class="linenr">19: </span>I rephrased it for him, in plain language a ten-year-old can understand:
<span class="linenr">20: </span>"""
</pre>
</div>

<p>
In this example we place whatever we want
summarized between the triple quotes. It’s
worth noting that we explain both before and
after the text to be summarized what our
intent is and who the target audience is for
the summary. This is to keep the API from
drifting after it processes a large block of
text.
</p>
</div>
</div>

<div id="outline-container-org301be77" class="outline-3">
<h3 id="org301be77"><span class="section-number-3">1.6</span> Completion</h3>
<div class="outline-text-3" id="text-1-6">
<p>
While all prompts are forms of completions it
can be helpful to think of text completion as
its own task in instances where you want the
API to pick up where you left off. Examples of
this include helping you write a summary or
writing lines of code where the API can infer
what should come next. In this prompt the API
will help write React components by completing
the code that’s sent to the API:
</p>

<div class="org-src-container">
<pre class="src src-text"><span class="linenr"> 1: </span>''''
<span class="linenr"> 2: </span>import React from 'react';
<span class="linenr"> 3: </span>const ThreeButtonComponent=()=&gt;(
<span class="linenr"> 4: </span>&lt;div&gt;
<span class="linenr"> 5: </span>&lt;p&gt;Button One&lt;p&gt;
<span class="linenr"> 6: </span>&lt;button className="button-green" onClick={this.handleButtonClick}&gt;Button One&lt;/button&gt;
<span class="linenr"> 7: </span>&lt;p&gt;Button Two&lt;/p&gt;
<span class="linenr"> 8: </span>&lt;button className="button-green" onClick={this.handleButtonClick}&gt;Button Two&lt;/button&gt;
<span class="linenr"> 9: </span>&lt;p&gt;Button Three&lt;/p&gt;
<span class="linenr">10: </span>&lt;button className="button-green" onClick={this.handleButtonClick}&gt;Button Three&lt;/button&gt;
<span class="linenr">11: </span>&lt;/div&gt;
<span class="linenr">12: </span>)
<span class="linenr">13: </span>''''
<span class="linenr">14: </span>import React from 'react';
<span class="linenr">15: </span>const HeaderComponent=()=&gt;(
</pre>
</div>

<p>
The API already has an understanding of the
React library and is able to continue the rest
of the code once it has an example of what the
user is trying to create.
</p>

<p>
In this next prompt the API is able to
determine the intent of the writer and help
continue the train of thought about vertical
farming. It’s also an example of where the
probability setting will keep the API focused
on the intent of the prompt or let it go off
on a tangent.
</p>

<div class="org-src-container">
<pre class="src src-text"><span class="linenr">1: </span>Vertical farming provides a novel solution for producing food locally, reducing transportation costs and
</pre>
</div>
</div>
</div>

<div id="outline-container-org021b950" class="outline-3">
<h3 id="org021b950"><span class="section-number-3">1.7</span> Factual responses</h3>
<div class="outline-text-3" id="text-1-7">
<p>
The API has a lot of knowledge that it’s
learned from the data that it was been trained
on. It also has the ability to provide
responses that sound very real but are in fact
made up. There are two ways to limit the
likelihood of the API making up an answer.
</p>

<ol class="org-ol">
<li>Provide a ground truth for the API.
If you provide the API with a body of text
to answer questions about (like a Wikipedia
entry) it will be less likely to
confabulate a response.</li>
<li>Use a low probability and show the API how to say “I don’t know”.
If the API understands that in cases where
it’s less certain about a response that
saying “I don’t know” or some variation is
appropriate, it will be less inclined to
make up answers.</li>
</ol>

<p>
In this example we give the API examples of
questions and answers it knows and then
examples of things it wouldn’t know and
provide question marks. We also set the
probability to zero so the API is more likely
to respond with a “?” if there is any doubt.
</p>

<div class="org-src-container">
<pre class="src src-text"><span class="linenr"> 1: </span>Q: Who is Batman?
<span class="linenr"> 2: </span>A: Batman is a fictional comic book character.
<span class="linenr"> 3: </span>###
<span class="linenr"> 4: </span>Q: What is torsalplexity?
<span class="linenr"> 5: </span>A: ?
<span class="linenr"> 6: </span>###
<span class="linenr"> 7: </span>Q: What is Devz9?
<span class="linenr"> 8: </span>A: ?
<span class="linenr"> 9: </span>###
<span class="linenr">10: </span>Q: Who is George Lucas?
<span class="linenr">11: </span>A: George Lucas is American film director and producer famous for creating Star Wars.
<span class="linenr">12: </span>###
<span class="linenr">13: </span>Q: What is the capital of California?
<span class="linenr">14: </span>A: Sacramento.
<span class="linenr">15: </span>###
<span class="linenr">16: </span>Q: What orbits the Earth?
<span class="linenr">17: </span>A: The Moon.
<span class="linenr">18: </span>###
<span class="linenr">19: </span>Q: Who <span style="color: #fffacd; background-color: #262626;">is Fred</span> Rickerson?
<span class="linenr">20: </span>A: ?
<span class="linenr">21: </span>###
<span class="linenr">22: </span>Q: What is an atom?
<span class="linenr">23: </span>A: An atom is a <span style="color: #ffe4b5; background-color: #262626;">tiny</span> particle that makes up everything.
<span class="linenr">24: </span>###
<span class="linenr">25: </span>Q: Who is Alvan Muntz?
<span class="linenr">26: </span>A: ?
<span class="linenr">27: </span>###
<span class="linenr">28: </span>Q: What is Kozar-09?
<span class="linenr">29: </span>A: ?
<span class="linenr">30: </span>###
<span class="linenr">31: </span>Q: How <span style="color: #ffe4b5; background-color: #262626;">many</span> moons does Mars have?
<span class="linenr">32: </span>A: Two, Phobos and Deimos.
<span class="linenr">33: </span>###
<span class="linenr">34: </span>Q:
</pre>
</div>
</div>
</div>

<div id="outline-container-org37b0ab4" class="outline-3">
<h3 id="org37b0ab4"><span class="section-number-3">1.8</span> Semantic search</h3>
<div class="outline-text-3" id="text-1-8">
<p>
The API lets you do semantic search over
documents. This means that you can provide a
query, such as a NL question or a statement,
and find documents that answer the question or
are semantically related to the statement. The
“documents” can be words, sentences,
paragraphs or even longer documents. For
example, if you provide documents ["White
House", "hospital", "school"] and query "the
president", you’ll get a different similarity
score for each document. The higher the
similarity score, the more semantically
similar the document is to the query (in this
example, “White House” will be most similar to
“the president”).
</p>

<p>
Each search query produces a different
distribution of scores for a fixed group of
documents. For instance, if you have a group
of documents that are summaries of books, the
query "sci-fi novels" might have a mean score
of 150 and standard deviation of 50, whereas
the query "cat training" might have a mean
score of 200 and standard deviation of 10, if
you were to search these queries against every
document in the group. The variation is a
consequence of the search setup, where the
query's probability (what is used to create
the score) is conditioned on the document's
probability.
</p>

<p>
If you need scores that don't vary by query,
you can randomly sample 50-100 documents for a
query and calculate the mean and standard
deviation, then normalize new scores for that
same query using that mean and standard
deviation.
</p>

<p>
The similarity score is a positive score that
usually ranges from 0 to 300 (but can
sometimes go higher), where a score above 200
usually means the document is semantically
similar to the query. At the moment, the score
is very useful for ranking (we’ve seen it
outperform many existing semantic ranking
approaches). For example, you can use it for
re-ranking the top few hundred examples from
an existing IR system.
</p>

<p>
One thing to keep in mind for semantic search
is the tradeoff between model accuracy and
speed, as speed is often a desired property of
search. We’ve found the “ada” model sufficient
for many search tasks, and it’s substantially
faster than the most capable model, “davinci”.
We encourage you to experiment with the
different models to see if “ada” or “babbage”
work for your search use case.
</p>

<p>
The search endpoint can query up to 200
documents in one request. If you have more
documents than that, you can divide them over
multiple requests (the document similarly
scores will stay the same across requests as
the query stays the same). One limitation to
keep in mind is that the query and longest
document must be below 2000 tokens together.
You can read more about the search endpoint in
the API Reference and try it out using the
Semantic Search Tool.</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: shane</p>
<p class="date">Created: 2021-02-15 Mon 03:18</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
